{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Computer Vision Engineer\n",
        "#\n",
        "# This project incorporates components from the Apache 2.0 licensed project.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "# ******************************************************************************\n",
        "# DISCLAIMER:\n",
        "#\n",
        "# This script is designed to download images and annotations from the Google Images\n",
        "# Dataset V7. It is important to note that the images and annotations in the\n",
        "# Google Images Dataset V7 are subject to specific licenses and usage terms. Users\n",
        "# of this script are strongly advised to refer to the Google Open Images website\n",
        "# (https://storage.googleapis.com/openimages/web/index.html) to verify and comply\n",
        "# with the licensing terms associated with both the images and annotations that\n",
        "# will be downloaded using this script.\n",
        "#\n",
        "# By using this script, you acknowledge and agree to adhere to the terms and\n",
        "# conditions set forth by the creators of the Google Images Dataset V7 for the\n",
        "# usage of both images and annotations. Any unauthorized use or violation of the\n",
        "# licensing terms is the sole responsibility of the user.\n",
        "# ******************************************************************************"
      ],
      "metadata": {
        "id": "9ePWOFXiLEqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install requirements\n",
        "\n",
        "!pip install boto3\n",
        "!pip install tqdm\n",
        "!pip install requests\n",
        "!pip install pandas\n",
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "-BR2GUuJh1Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hMExsxheZmeR"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "import os\n",
        "import shutil\n",
        "import argparse\n",
        "import sys\n",
        "\n",
        "import requests\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def process(classes, data_out_dir, yolov8_format, max_number_images_per_class):\n",
        "\n",
        "    if max_number_images_per_class is None:\n",
        "        max_number_images_per_class = sys.maxsize\n",
        "\n",
        "    train_data_url = 'https://storage.googleapis.com/openimages/v6/oidv6-train-annotations-bbox.csv'\n",
        "    val_data_url = 'https://storage.googleapis.com/openimages/v5/validation-annotations-bbox.csv'\n",
        "    test_data_url = 'https://storage.googleapis.com/openimages/v5/test-annotations-bbox.csv'\n",
        "\n",
        "    downloader_url = 'https://raw.githubusercontent.com/openimages/dataset/master/downloader.py'\n",
        "\n",
        "    class_names_all_url = 'https://storage.googleapis.com/openimages/v7/oidv7-class-descriptions.csv'\n",
        "\n",
        "    for url in [train_data_url, val_data_url, test_data_url, class_names_all_url, downloader_url]:\n",
        "        if not os.path.exists(url.split('/')[-1]):\n",
        "            print('downloading {}...'.format(url.split('/')[-1]))\n",
        "            r = requests.get(url)\n",
        "            with open(url.split('/')[-1], 'wb') as f:\n",
        "                f.write(r.content)\n",
        "\n",
        "    class_ids = []\n",
        "\n",
        "    classes_all = pd.read_csv(class_names_all_url.split('/')[-1])\n",
        "\n",
        "    for class_ in classes:\n",
        "        if class_ not in list(classes_all['DisplayName']) or class_ not in list(classes_all['DisplayName']):\n",
        "            raise Exception('Class name not found: {}'.format(class_))\n",
        "        class_index = list(classes_all['DisplayName']).index(class_)\n",
        "        class_ids.append(classes_all['LabelName'].iloc[class_index])\n",
        "\n",
        "    image_list_file_path = os.path.join('.', 'image_list_file')\n",
        "    if os.path.exists(image_list_file_path):\n",
        "        os.remove(image_list_file_path)\n",
        "\n",
        "\n",
        "    image_list_file_list = []\n",
        "    for j, url in enumerate([train_data_url, val_data_url, test_data_url]):\n",
        "        image_list_file_per_class = [[] for j in class_ids]\n",
        "        filename = url.split('/')[-1]\n",
        "        with (open(filename, 'r') as f):\n",
        "            line = f.readline()\n",
        "            while len(line) != 0:\n",
        "                id, _, class_name, _, x1, x2, y1, y2, _, _, _, _, _ = line.split(',')[:13]\n",
        "                if class_name in class_ids and id not in image_list_file_list \\\n",
        "                    and len(image_list_file_per_class[class_ids.index(class_name)]) < max_number_images_per_class:\n",
        "                    image_list_file_list.append(id)\n",
        "                    image_list_file_per_class[class_ids.index(class_name)].append(id)\n",
        "                    with open(image_list_file_path, 'a') as fw:\n",
        "                        fw.write('{}/{}\\n'.format(['train', 'validation', 'test'][j], id))\n",
        "                line = f.readline()\n",
        "\n",
        "            f.close()\n",
        "\n",
        "    out_dir = './.out'\n",
        "    shutil.rmtree(out_dir, ignore_errors=True)\n",
        "    os.system('python downloader.py {} --download_folder={}'.format(image_list_file_path, out_dir))\n",
        "\n",
        "    DATA_ALL_DIR = out_dir\n",
        "\n",
        "    for set_ in ['train', 'val', 'test']:\n",
        "        for dir_ in [os.path.join(data_out_dir, set_),\n",
        "                     os.path.join(data_out_dir, set_, 'imgs'),\n",
        "                     os.path.join(data_out_dir, set_, 'anns')]:\n",
        "            if os.path.exists(dir_):\n",
        "                shutil.rmtree(dir_)\n",
        "            os.makedirs(dir_)\n",
        "\n",
        "    for j, url in enumerate([train_data_url, val_data_url, test_data_url]):\n",
        "        filename = url.split('/')[-1]\n",
        "        set_ = ['train', 'val', 'test'][j]\n",
        "        print(filename)\n",
        "        with open(filename, 'r') as f:\n",
        "            line = f.readline()\n",
        "            while len(line) != 0:\n",
        "                id, _, class_name, _, x1, x2, y1, y2, _, _, _, _, _ = line.split(',')[:13]\n",
        "                if class_name in class_ids:\n",
        "                    if os.path.exists(os.path.join(DATA_ALL_DIR, '{}.jpg'.format(id))):\n",
        "                        if not os.path.exists(os.path.join(data_out_dir, set_, 'imgs', '{}.jpg'.format(id))):\n",
        "                            shutil.copy(os.path.join(DATA_ALL_DIR, '{}.jpg'.format(id)),\n",
        "                                        os.path.join(data_out_dir, set_, 'imgs', '{}.jpg'.format(id)))\n",
        "                        with open(os.path.join(data_out_dir, set_, 'anns', '{}.txt'.format(id)), 'a') as f_ann:\n",
        "                            # class_id, xc, yx, w, h\n",
        "                            x1, x2, y1, y2 = [float(j) for j in [x1, x2, y1, y2]]\n",
        "                            xc = (x1 + x2) / 2\n",
        "                            yc = (y1 + y2) / 2\n",
        "                            w = x2 - x1\n",
        "                            h = y2 - y1\n",
        "\n",
        "                            f_ann.write('{} {} {} {} {}\\n'.format(int(class_ids.index(class_name)), xc, yc, w, h))\n",
        "                            f_ann.close()\n",
        "\n",
        "                line = f.readline()\n",
        "\n",
        "    shutil.rmtree(out_dir, ignore_errors=True)\n",
        "\n",
        "    if yolov8_format:\n",
        "        for set_ in ['train', 'val', 'test']:\n",
        "            for dir_ in [os.path.join(data_out_dir, 'images', set_),\n",
        "                         os.path.join(data_out_dir, 'labels', set_)]:\n",
        "                if os.path.exists(dir_):\n",
        "                    shutil.rmtree(dir_)\n",
        "                os.makedirs(dir_)\n",
        "\n",
        "            for filename in os.listdir(os.path.join(data_out_dir, set_, 'imgs')):\n",
        "                shutil.copy(os.path.join(data_out_dir, set_, 'imgs', filename), os.path.join(data_out_dir, 'images', set_, filename))\n",
        "            for filename in os.listdir(os.path.join(data_out_dir, set_, 'anns')):\n",
        "                shutil.copy(os.path.join(data_out_dir, set_, 'anns', filename), os.path.join(data_out_dir, 'labels', set_, filename))\n",
        "\n",
        "            shutil.rmtree(os.path.join(data_out_dir, set_))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['Duck', 'Dog']  # list containing all the classes you will download from the open images dataset v7\n",
        "\n",
        "out_dir = './data'\n",
        "\n",
        "max_number_images_per_class = 200\n",
        "\n",
        "yolov8_format = True\n",
        "\n",
        "process(classes, out_dir, yolov8_format, max_number_images_per_class)"
      ],
      "metadata": {
        "id": "RVWBpFLxeQsw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "418e9c5c-74c4-4640-873d-2b176e83abfb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading oidv6-train-annotations-bbox.csv...\n",
            "downloading validation-annotations-bbox.csv...\n",
            "downloading test-annotations-bbox.csv...\n",
            "downloading oidv7-class-descriptions.csv...\n",
            "downloading downloader.py...\n",
            "oidv6-train-annotations-bbox.csv\n",
            "validation-annotations-bbox.csv\n",
            "test-annotations-bbox.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zip the data directory\n",
        "\n",
        "!zip -r data.zip /content/data"
      ],
      "metadata": {
        "id": "z5cAay6Sd7p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "dBXbyXXCeFkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy data to your Google Drive\n",
        "\n",
        "!scp '/content/data.zip' '/content/gdrive/My Drive/data.zip'"
      ],
      "metadata": {
        "id": "PQWt6zgveKE7"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}